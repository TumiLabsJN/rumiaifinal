# Revision List - 081435

## Issues to Address

### 1. Empty Error Logs
**Issue**: Why was the error logs file empty if we ran into issues?

---

### 2. Service Contract Code Missing
**Issue**: What happened to the service contract code we created? If we had issues shouldn't they have been activated?

---

### 3. Placeholder Precompute Functions
**Issue**: Some precompute functions (metadata_analysis_metrics, person_framing_metrics, scene_pacing_metrics) are still placeholders

---

### 4. Incomplete Flow Execution
**Issue**: Why only 5/7 flows completed? (missing person_framing and scene_pacing)
- ✅ creative_density
- ✅ emotional_journey
- ✅ speech_analysis
- ✅ visual_overlay_analysis
- ✅ metadata_analysis
- ❌ person_framing
- ❌ scene_pacing

---

### 5. Timeout Issue
**Issue**: Why did the timeout occur?

---

### 6. CRITICAL: Wrong Output Format
**Issue**: Why was the output not in CoreBlock format? 

**Command executed**:
```bash
export USE_ML_PRECOMPUTE=true
export USE_CLAUDE_SONNET=true
export OUTPUT_FORMAT_VERSION=v2
./venv/bin/python scripts/rumiai_runner.py "https://www.tiktok.com/@pgf0vlqrm7/video/7515849242703973662?q=%23herbsforhealth&t=1749119718525"
```

**Wrong output** (Narrative text in JSON wrapper):
`\\wsl$\Ubuntu\home\jorge\rumiaifinal\insights\7515849242703973662\speech_analysis\speech_analysis_complete_20250807_120913.json`
- Contains: `"response": "Based on the provided data, here's an analysis..."`

**Expected output** (CoreBlock format for ML training):
`\\wsl$\Ubuntu\home\jorge\rumiaifinal\insights\7515849242703973662\speech_analysis\speech_analysis_result_20250806_183819.txt`
- Contains: Structured JSON with 6 blocks (e.g., `speechCoreMetrics`, `speechDynamics`, etc.)

---

#### Root Cause Analysis

**Critical Discovery**: The prompts were changed between August 6th and August 7th:

1. **August 6th (Working)**:
   - Outputs had proper CoreBlock structure
   - Example: `creative_density_result_20250806_161914.txt` contains `densityCoreMetrics`, `densityDynamics`, etc.
   
2. **August 7th (Broken)**:
   - Outputs are narrative text
   - Prompts in `settings.py` now say "Analyze..." and "Provide insights..." instead of requesting JSON structure

#### Architecture Mismatch

Based on `ML_FEATURES_DOCUMENTATION.md` analysis:

**Feature Sources**:
- **60% marked "Computed"**: Should be calculated by precompute functions
- **30% from ML Services**: Raw data from OCR, YOLO, MediaPipe, etc.
- **10% from Claude**: Confidence scores and structure

**The Fundamental Problem**:
1. Most CoreBlock features (300+ features) are meant to be **calculated by precompute functions**, not generated by Claude
2. Current precompute functions are **placeholders** (return empty dicts)
3. Prompts were changed from structured JSON requests to narrative "insights"

**What Should Happen**:
1. Precompute functions calculate all "Computed" metrics
2. Claude receives these pre-calculated metrics
3. Claude returns them in CoreBlock JSON structure with confidence scores

**What's Actually Happening**:
1. Precompute functions return empty/minimal data
2. Claude gets narrative prompts asking for "insights"
3. Claude returns narrative text instead of structured CoreBlock JSON

#### Solution Required

The working prompts (Aug 6) likely had format like:
```
Given these precomputed metrics:
{metrics}

Return them in this exact JSON structure:
{
  "densityCoreMetrics": {...},
  "densityDynamics": {...},
  "densityInteractions": {...},
  "densityKeyEvents": {...},
  "densityPatterns": {...},
  "densityQuality": {...}
}

Add confidence scores based on data completeness.
```

**To fix**:
1. Restore structured prompts that request CoreBlock JSON format
2. Implement actual precompute functions (not placeholders)
3. Ensure OUTPUT_FORMAT_VERSION=v2 enforces structured output validation